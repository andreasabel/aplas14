\section{Strong Normalization}
\label{sec:sn}

\input{sn}

\citet{raamsdonk:perpetualReductions} pioneered an ``inductive''
definition of strongly normalizing terms $\SN$, namely the least set
closed under introductions, formation of neutral (=stuck) terms, and
weak head expansion.  We adapt their technique from lambda-calculus to
$\lambdalater$; herein, it is crucial to work with well-typed terms to
avoid junk like $\tfst\,\lambda x x$ which does not exist in pure
lambda-calculus.  To formulate a deterministic weak head evaluation,
we make use of the \emph{evaluation contexts} $\vE : \ECxt$
\[
  \vE ::= \_\;u \mid \fst\_ \mid \snd\_ \mid \_\,∗\,u \mid (\tnext\;t)\,∗\,\_
.\]
Since weak head reduction does not go into introductions which include
$\lambda$-abstraction, it does not go under binders, leaving typing
context \Gam{} fixed. 
 
\input{TermShape}

\input{SN}
\input{AntiRename}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "aplas14.tex"
%%% End: 
